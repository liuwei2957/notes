### collection

 存放单一元素 

![](https://mmbiz.qpic.cn/mmbiz_png/og5r7PHGHogIVfibksSZVTgKDVVTRrDeibyE5q0VfMIHfQspLicibz0j05ibrib20wWXSwE6zzMsHwZQPbdkWZGXYN2Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### list

有序，可重复

![](https://mmbiz.qpic.cn/mmbiz_png/og5r7PHGHogIVfibksSZVTgKDVVTRrDeibNRnsm3Z5WdqKvXKZ3ic82Ba6n6WghUfqdcB6KDibdAdITo8D51LNzmgQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

1.  实现方式有 LinkedList 和 ArrayList 两种 
2.   ArrayList 是用数组来实现的， 而数组和链表的最大区别就是**数组是可以随机访问的（random access）** ， 在数组里可以通过下标用 O(1) 的时间拿到任何位置的数，而链表则做不到，只能从头开始逐个遍历 
3.  **改查选择 ArrayList** ， **增删在尾部的选择 ArrayList** ， **其他情况下，如果时间复杂度一样，推荐选择 ArrayList，因为内存使用更有效率** 

#####  ArrayList

 ArrayList（int initialCapacity）不会初始化数组 , 不适合做队列 

![](https://mmbiz.qpic.cn/mmbiz_png/HnUd56VHiaf2mdKnBcG5DDFwIjicEibw088clo3zSkK4UaP5oe6w5ZK4u0VYwWIATkJiaM6KRSdq6ic3Xic23iatzbgMQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

1.  `new ArrayList()`会将`elementData` 赋值为 DEFAULTCAPACITY_EMPTY_ELEMENTDATA，`new ArrayList(0)`会将`elementData` 赋值为 EMPTY_ELEMENTDATA，EMPTY_ELEMENTDATA添加元素会扩容到容量为`1`，而DEFAULTCAPACITY_EMPTY_ELEMENTDATA扩容之后容量为`10` 
2. ArrayList可以自动扩容，不传初始容量或者初始容量是`0`，都会初始化一个空数组，但是如果添加元素，会自动进行扩容，所以，创建ArrayList的时候，给初始容量是必要的
3. `Arrays.asList()`方法返回的是的`Arrays`内部的ArrayList，用的时候需要注意
4. `subList()`返回内部类，不能序列化，和ArrayList共用同一个数组
5. 迭代删除要用，迭代器的`remove`方法，或者可以用倒序的`for`循环
6. ArrayList重写了序列化、反序列化方法，避免序列化、反序列化全部数组，浪费时间和空间
7. `elementData`不使用`private`修饰，可以简化内部类的访问

#####  ArrayBlockingQueue

 内部实现就是一个环形队列，它是一个定长队列，内部是用一个定长数组来实现的 ， 简单点说就是使用两个偏移量来标记数组的读位置和写位置，如果超过长度就折回到数组开头，前提是它们是定长数组 

##### Vector

1.   Vector 和 ArrayList 一样，也是继承自 java.util.AbstractList，底层也是用数组来实现的 

2. ArrayList 是 扩容**1.5 倍** ，Vector是 **扩容两倍** 

   

####  Queue & Deque

 Queue 是一端进另一端出的线性数据结构；而 Deque 是两端都可以进出的 

![](https://mmbiz.qpic.cn/mmbiz_png/og5r7PHGHogIVfibksSZVTgKDVVTRrDeibWgYVBcDqYfSCc4AJFFHmywBZPseoqRVR2TZMjEGWvCMmmNSq3EDsbg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

1.  如果想实现「普通队列 - 先进先出」的语义，就使用 LinkedList 或者 ArrayDeque 来实现 ， 如果想实现「优先队列」的语义，就使用 PriorityQueue ， 如果想实现「栈」的语义，就使用 ArrayDeque 

##### PriorityQueue

 堆其实就是一种特殊的队列——优先队列 ， 不是按照进队列的时间顺序，而是按照每个元素的**优先级**来比拼，**优先级高的在堆顶** 

1.  heap 其实是一个**抽象的数据结构**，或者说是**逻辑上的数据结构**，并不是一个物理上真实存在的数据结构 
2.  heap 其实有很多种实现方式，比如 binomial heap, Fibonacci heap 等等。最经典的就是 **binary heap 二叉堆**，也就是用一棵**完全二叉树**来实现的 ， 其实是用**数组**来实现的 ，所以 binary heap/PriorityQueue 实际上是用**数组**来实现的
3.  siftUp() ： **先把新元素加入数组的末尾，再通过不断比较与 parent 的值的大小，决定是否交换，直到满足堆序性为止** ， 时间复杂度就是 `O(logn)` 
4.  siftDown() ： **先把数组的末位元素加到顶端，再通过不断比较与左右孩子的值的大小，决定是否交换，直到满足堆序性为止** ， 时间复杂度就是 `O(logn)` 
5.  heapify() ：从最后一个非叶子节点开始，从后往前做 `siftDown()`， 因为叶子节点没必要操作嘛，已经到了最下面了 ，时间复杂度是 O(n) 

#####  LinkedList &ArrayDeque

1.  ArrayDeque 是一个可扩容的数组，LinkedList 是链表结构 
2.  ArrayDeque 里不可以存 null 值，但是 LinkedList 可以 
3.  ArrayDeque 在操作头尾端的增删操作时更高效，但是 LinkedList 只有在当要移除中间某个元素且已经找到了这个元素后的移除才是 O(1) 的 
4.  ArrayDeque 在内存使用方面更高效

##### Stack

 Stack 在语义上是 **后进先出（LIFO）** 的线性数据结构 

1. 虽然 Java 中有 Stack 这个类，但是官方文档都说不让用了 ， 因为 Vector 已经过被弃用了，而 Stack 是继承 Vector 的 
2.  想实现 Stack 的语义，就用 ArrayDeque 

#### set

无序，不重复的

![](https://mmbiz.qpic.cn/mmbiz_png/og5r7PHGHogIVfibksSZVTgKDVVTRrDeibsTLnCFOPgjkT3jSTicYYCd1WxnDZDwYcicbUowJgEHovxCy2JhribNVHw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

1.  **HashSet**: 采用 Hashmap 的 key 来储存元素，主要特点是无序的，基本操作都是 O(1) 的时间复杂度，很快 
2.  **LinkedHashSet**: 这个是一个 HashSet + LinkedList 的结构，特点就是既拥有了 O(1) 的时间复杂度，又能够保留插入的顺序 
3.  **TreeSet**: 采用红黑树结构，特点是可以有序，可以用自然排序或者自定义比较器来排序；缺点就是查询速度没有 HashSet 快 
4.  每个 Set 的**底层实现**其实就是对应的 Map ， **数值放在 map 中的 key 上，value 上放了个 PRESENT，是一个静态的 Object，相当于 place holder，每个 key 都指向这个 object** 

### map

 存放 key-value 键值对 

#### hashmap

1.  由**数组和链表组合构成**的数据结构 
2.  **java8之前是头插法** ， 就是说新来的值会取代原有的值，原有的值就顺推到链表中去 ， 因为写这个代码的作者认为后来的值被查找的可能性更大一点，提升查找的效率 ，**单链表的头插入方式，同一位置上新元素总会被放在链表的头部位置**，在旧数组中同一条Entry链上的元素，通过重新计算索引位置后，有可能被放到了新数组的不同位置上， 修改了原来链表中节点的引用关系 ， 如果这个时候去取值，有可能出现Infinite Loop 
3.  **在java8之后，都是所用尾部插入了**  ， **使用头插**会改变链表的上的顺序，但是如果**使用尾插**，在扩容时会保持链表元素原本的顺序，就不会出现链表成环的问题了 
4.  put/get方法都没有加同步锁，多线程情况最容易出现的就是：无法保证上一秒put的值，下一秒get的时候还是原值，所以线程安全还是无法保证 

##### 线程不安全

 在jdk1.7中，在多线程环境下，扩容时会造成环形链或数据丢失 ， 在jdk1.8中，在多线程环境下，会发生数据覆盖的情况 ， 在jdk1.8中，在多线程环境下，会发生数据覆盖的情况 

#####  扩容机制 

Capacity：HashMap当前长度 ， LoadFactor：负载因子，默认值0.75f 

1.  扩容：创建一个新的Entry空数组，长度是原数组的2倍 
2.  ReHash：遍历原Entry数组，把所有的Entry重新Hash到新数组 

#####  默认初始化长度 

1. 16， 这样是为了位运算的方便，**位与运算比算数计算的效率高了很多**，之所以选择16，是为了方便将Key映射到index的算法 ，index=(n-1)&hash, 在使用不是2的幂的数字的时候，Length-1的值是所有二进制位全为1，这种情况下，index的结果等同于HashCode后几位的值 , 只要输入的HashCode本身分布均匀，Hash算法的结果就是均匀的 
2.  位运算(&)效率要比代替取模运算(%)高很多，主要原因是位运算直接对内存数据进行操作，不需要转成十进制，因此处理速度非常快。 
3.  如果用户制定了初始容量，那么HashMap会计算出比该数大的第一个2的幂作为初始容量 ， 另外，在扩容的时候，也是进行成倍的扩容 

#####  转化为红黑树

 根据泊松分布，在负载因子默认为0.75的时候，单个hash槽内元素个数为8的概率小于百万分之一，所以将7作为一个分水岭，等于7的时候不转换，大于等于8的时候才进行转换，小于等于6的时候就化为链表 

#####  **快速失败** 

 **快速失败（fail—fast）**是java集合中的一种机制， 在用迭代器遍历一个集合对象时，如果遍历过程中对集合对象的内容进行了修改（增加、删除、修改），则会抛出Concurrent Modification Exception 

1.  迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量 ， 集合在被遍历期间如果内容发生变化，就会改变modCount的值 
2.  每当迭代器使用hashNext()/next()遍历下一个元素之前，都会检测modCount变量是否为expectedmodCount值，是的话就返回遍历；否则抛出异常，终止遍历 
3.  如果集合发生变化时修改modCount值刚好又设置为了expectedmodCount值，则异常不会抛出 
4.  java.util包下的集合类都是快速失败的，不能在多线程下发生并发修改 

#####  **安全失败**

 java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改 

####  Hashtable  

 Hashtable 是不允许键或值为 null 的 ， 这是因为Hashtable使用的是**安全失败机制（fail-safe）**，这种机制会使你此次读到的数据不一定是最新的数据 ， 如果你使用null值，就会使得其无法判断对应的key是不存在还是为空，因为你无法再调用一次contain(key）来对key是否存在进行判断，ConcurrentHashMap同理 

1.  **实现方式不同**：Hashtable 继承了 Dictionary类，而 HashMap 继承的是 AbstractMap 类 
2.  **初始化容量不同**：HashMap 的初始容量为：16，Hashtable 初始容量为：11，两者的负载因子默认都是：0.75 
3.  **扩容机制不同**：当现有容量大于总容量 * 负载因子时，HashMap 扩容规则为当前容量翻倍，Hashtable 扩容规则为当前容量翻倍 + 1 
4.  **迭代器不同**：HashMap 中的 Iterator 迭代器是 fail-fast 的，而 Hashtable 的 Enumerator 不是 fail-fast 的 

####  ConcurrentHashMap

##### jdk1.7

1.  ConcurrentHashMap 采用了**分段锁**技术，其中 Segment 继承于 ReentrantLock 
2.  理论上 ConcurrentHashMap 支持 CurrencyLevel (Segment 数组数量)的线程并发 
3. put流程： 首先第一步的时候会尝试获取锁，如果获取失败肯定就有其他线程存在竞争，则利用 `scanAndLockForPut()` 自旋获取锁 ， 如果重试的次数达到了 `MAX_SCAN_RETRIES` 则改为阻塞锁获取，保证能获取成功 
4.  get 流程，只需要将 Key 通过 Hash 之后定位到具体的 Segment ，再通过一次 Hash 定位到具体的元素上 
5.  由于 HashEntry 中的 value 属性是用 volatile 关键词修饰的，保证了内存可见性，所以每次获取时都是最新值 ， **不需要加锁** 

#####  jdk1.8

 抛弃了原有的 Segment 分段锁，而采用了 `CAS + synchronized` 来保证并发安全性 ， 跟HashMap很像，也把之前的HashEntry改成了Node，但是作用不变，把值和next采用了volatile去修饰，保证了可见性，并且也引入了红黑树，在链表大于一定值的时候会转换（默认是8） 

###### put流程

根据 key 计算出 hashcode  ， 判断是否需要进行初始化 ， 即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功 ， 如果当前位置的 `hashcode == MOVED == -1`,则需要进行扩容 ， 如果都不满足，则利用 synchronized 锁写入数据 ， 如果数量大于 `TREEIFY_THRESHOLD` 则要转换为红黑树 

######  transfer

 帮助迁移元素，因为扩容的第一次初始化新表（扩容后的新表）这个动作，只能由一个线程完成。其他线程都是在帮助迁移元素到新数组 

###  集合线程安全

1. 同步容器直接保证单个操作的线程安全性，但是无法保证复合操作的线程安全，遇到这种情况时，必须要通过主动加锁的方式来实现 ， 同步容易由于对其所有方法都加了锁，这就导致多个线程访问同一个容器的时候，只能进行顺序访问，即使是不同的操作，也要排队，如get和add要排队执行。这就大大的降低了容器的并发能力 
2.  Copy-On-Write容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器 
3.  CopyOnWriteArrayList中add/remove等写方法是需要加锁的，而读方法是没有加锁的 ， 这里读到的数据可能不是最新的 