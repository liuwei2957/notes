### mysql服务器逻辑架构

1. Server层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务 功能，以及所有的内置函数(如日期、时间、数学和加密函数等)，所有跨存储引擎的功能都在 这一层实现，比如存储过程、触发器、视图等
2. 而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、 Memory等多个存储引擎，存储引擎api包含几十个底层函数，用于执行诸如，开始一个事务，根据主键提取一行记录等操作，存储引擎不会去解析sql(Innodb会解析外键定义，因为mysql服务器本身没有实现该功能)

### sql执行顺序

#### 查询

1. 建立连接，建立连接的过程通常是比较复杂的，所以建议在使用中要尽量减少建立连接的动作，也就是尽量使用长连接，但是全部使用长连接后，你可能会发现，有些时候MySQL占用内存涨得特别快，这是因为 MySQL在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候 才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（1. 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连 2. 如果你用的是MySQL5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证， 但是会将连接恢复到刚刚创建完时的状态）
2. 查询缓存，之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是 查询的结果（但是大多数情况下建议不要使用查询缓存，为什么呢?因为查询缓存往往弊大于利，查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库 来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。 比如，一个系统配置表，那这张表上的查询才适合使用查询缓存，MySQL 8.0版本直接将查询缓存的整块功能删掉了，也就是说8.0开始彻底没有这个功能了）
3. 分析器，分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条SQL语句，MySQL需要识别出里面的字符串分别是什么，代表什么，做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则， 判断你输入的这个SQL语句是否满足MySQL语法
4. 优化器，优化器是在表里面有多个索引的时候，决定使用哪个索引;或者在一个语句有多表关联(join)的时候，决定各个表的连接顺序
5. 执行器，开始执行的时候，要先判断一下你对这个表T有没有执行查询的权限，如果没有，就会返回没有 权限的错误，如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口，第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，直到取到这个表的最后一行，执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端，你会在数据库的慢查询日志中看到一个rows_examined的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的

#### 更新

如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高，为此MySQL引入了WAL技术，WAL的全称是Write- Ahead Logging，它的关键点就是先写日志，再写磁盘，具体来说，当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里 面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录4GB的操作。从头开始写，写到末尾就又回到开头循环写，write pos是当前记录的位置，一边写一边后移，checkpoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件，有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个 能力称为crash-safe

##### binlog

redo log是 InnoDB引擎特有的日志，而Server层也有自己的日志，称为binlog(归档日志)，只依靠binlog是没有crash-safe能力的，InnoDB使用另外一套日志系统— — 也就是redo log来实现crash-safe能力

##### 不同点

1. redolog是InnoDB引擎特有的;binlog是MySQL的Server层实现的，所有引擎都可以使用
2. redolog是物理日志，记录的是“在某个数据页上做了什么修改”;binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”
3. redolog是循环写的，空间固定会用完;binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志

##### 执行流程

1. 执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一 行所在的数据页本来就在内存中，就直接返回给执行器;否则，需要先从磁盘读入内存，然 后再返回

2. 执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行 数据，再调用引擎接口写入这行新数据

3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到redolog里面，此时redolog处 于prepare状态。然后告知执行器执行完成了，随时可以提交事务

4. 执行器生成这个操作的binlog，并把binlog写入磁盘

5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的redolog改成提交(commit)状态，更新完成

   最后三步看上去有点“绕”，将redo log的写入拆成了两个步骤:prepare和commit，这就是"两阶段提交"

##### 为什么必须有“两阶段提交”

这是为了让两份日志之间的逻辑一致

假设当前ID=2的行，字段c的值是0，要更新1

1. 先写redo log后写binlog。假设在redo log写完，binlog还没有写完的时候，MySQL进程异 常重启。由于我们前面说过的，redo log写完之后，系统即使崩溃，仍然能够把数据恢复回 来，所以恢复后这一行c的值是1。 但是由于binlog没写完就crash了，这时候binlog里面就没有记录这个语句。因此，之后备份 日志的时候，存起来的binlog里面就没有这条语句。 然后你会发现，如果需要用这个binlog来恢复临时库的话，由于这个语句的binlog丢失，这 个临时库就会少了这一次更新，恢复出来的这一行c的值就是0，与原库的值不同

2. 先写binlog后写redo log。如果在binlog写完之后crash，由于redo log还没写，崩溃恢复以 后这个事务无效，所以这一行c的值是0。但是binlog里面已经记录了“把c从0改成1”这个日 志。所以，在之后用binlog来恢复的时候就多了一个事务出来，恢复出来的这一行c的值就是 1，与原库的值不同

   可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的 状态不一致

#### redolog

1. redo log用于保证crash-safe能力。innodb_flush_log_at_trx_commit这个参数设置成1的时候， 表示每次事务的redo log都直接持久化到磁盘。这个参数建议设置成1，这样可以保证 MySQL异常重启之后数据不丢失

### 事务的ACID特性

#### 原子性

一个事务必须被视为一个不可分割的最小工作单元，整个事务中的所有操作要么全部提交成功，要么全部失败回滚

#### 一致性

数据库总是从一个一致性的状态转移到另外一个一致性的状态，因为事务最终没有提交，所以事务中所做的修改也不会保存到数据库中

#### 隔离性

通常来说，一个事务所做的修改在最终提交以前，对其他事务是不可见的

#### 持久性

一旦事务提交，则其所做的修改就会永久保存到数据库中，即使系统崩溃，修改的数据也不会丢失(不可能有能做到100%的持久性保证策略)

### 隔离性

1. 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到

2. 读提交是指，一个事务提交之后，它做的变更才会被其他事务看到

3. 可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一 致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的

4. 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突 的时候，后访问的事务必须等前一个事务执行完成，才能继续执行

   在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离 级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在“读提交”隔离级 别下，这个视图是在每个SQL语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离 级别下直接返回记录上的最新值，没有视图概念;而“串行化”隔离级别下直接用加锁的方式来避免并行访问

#### 事务隔离的实现

在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值，当没有事务再需要用到这些回滚日志时，也就是系统里没有比这个回滚日志更早的read-view的时候，回滚日志会被删除

### 索引

1. 哈希索引，哈希表这种结构适用于只有等值查询的场景，比如Memcached及其他一些NoSQL引擎
2. 有序数组，有序数组在等值查询和范围查询场景中的性能就都非常优秀，在需要更新数据的时候就麻烦 了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高，有序数组索引只适用于静态存储引擎
3. 二叉搜索树，二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上，为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N叉”树。这里，“N叉”树中的“N”取决于数据块的大小

#### InnoDB 的索引模型

在InnoDB中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表

1. 主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为聚簇索引(clustered index)
2. 非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引 (secondary index)

#### 索引维护

B+树为了维护索引有序性，在插入新值的时候需要做必要的维护，需要申请一个新的 数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响，除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中， 整体空间利用率降低大约50%，当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合 并的过程，可以认为是分裂过程的逆过程

1. 自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂
2. 而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高
3. 主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小
4. 由于InnoDB是索引组织表，一般情况下建议创建一个自增主键，这样非主键索引占用的 空间最小
5. 只有一个索引，该索引必须是唯一索引适合用业务字段直接做主键
6. 由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用 的性能优化手段

#### 最左前缀原则

1. B+树这种索引结构，可以利用索引的“最左前缀”，来定位记录，这个最左 前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符
2. 索引项是按照索引定义里面出现的字段顺序排序的

#### 联合索引

评估标准是，索引的复用能力以及空间占用

1. 第一原则是，如果通过调整顺序，可 以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的

#### 索引下推

1. 在MySQL 5.6之前，只能从找到满足条件的索引开始一个个回表。到主键索引上找出数据行，再对比字段值
2. 而MySQL 5.6 引入的索引下推优化(index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数

### 锁

#### 全局锁

就是对整个数据库实例加锁。MySQL提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)，使用场景是，做全库逻辑备份

#### 表级锁

##### 表锁

lock tables …read/write

##### 元数据锁（meta data lock，MDL)

MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，保证读写的正确性，当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁，加字段(在alter table语句里面 设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后 面的业务语句，先放弃。之后开发人员或者DBA再通过重试命令重复这个过程)

#### 行锁

在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放

### 死锁

当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致 这几个线程都进入无限等待的状态，称为死锁

#### 两种策略

1. 一种策略是，直接进入等待，直到超时，超时时间设置不能太短，太短的话，会出现很多误伤
2. 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行

#### 死锁检测

每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是O(n)的操作，死锁检测要耗费大量的CPU资源

1. 如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉
2. 另一个思路是控制并发度，比如同一行同时最多只有10个线程在更新，那么死锁检测的成本很低
3. 通过将一行改成逻辑上的多行来减少锁冲突

#### 解决办法

1. 检测到死锁的循环依赖，立即返回一个错误
2. 当查询的时间达到锁等待超时的设定后放弃锁请求
3. Innodb是将持有最少行级排他锁的事务进行回滚

### 事务日志

事务日志可以帮助提高事务的效率，使用事务日志，存储引擎在修改表的数据时只需要修改其内存拷贝，再把该修改行为记录持久到硬盘上的事务日志中，而不用每次都将修改的数据本身持久到磁盘，事务日志采用的是追加的方式，，因此写日志的操作是磁盘上一小块区域的顺序io，事务日志持久化后，内存中被修改的数据在后台可以慢慢地刷回到磁盘，通常称为预写日志，修改数据需要写两次磁盘，如果数据的修改已经记录到事务日志并持久化，但数据本身还没有写回磁盘，此时系统崩溃，存储引擎在重启时能够自动恢复这部分修改的数据

### 两阶段锁定协议

在事务执行过程中，随时都可以执行锁定，但锁只有在执行commit或者rollback时才会释放，并且所有的锁是在同一时刻被释放

### MVCC

MVCC的实现，是通过保存数据在某个时间点的快照来实现的，不管需要执行多长时间，每个事务看到的数据都是一致的，根据事务的开始时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的，MVCC只在READ COMMITTED和REPEATABLE READ两个隔离级别下工作

#### Inonodb的实现

Innodb的MVCC，是通过在每行记录后面保存两个隐藏的列来实现的，这两个列，一个保存了行的创建版本号，一个保存行的删除版本号，每开始一个新的事务，系统版本号都会自动递增，事务开始时刻的版本号会作为事务的版本号，insert：innodb为新插入的每一行保存当前系统版本号作为行版本号，delete：innodb为删除的每一行保存当前系统版本号作为行删除标识，update：innodb为插入一行新记录，保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为行删除标识

#### RR级别MVCC

Innodb会根据以下两个条件检查每行记录

1. Innodb只查找版本早于当前事务版本的数据行(也就是说，行的系统版本号小于等于事务的系统版本号)，这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的
2. 行的删除版本要么未定义，要么大于当前事务版本号，这样可以确保事务读取到的行，在事务开始之前未被删除

