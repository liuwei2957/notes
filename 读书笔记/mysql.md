

#### 数据删除流程

InnoDB引擎只会把这个记录标记为删除。如果之后要再插入一个记录时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小，如果我们删掉了一个数据页上的所有记录，整个数据页就可以被复用了，数据页的复用跟记录的复用是不同的，记录的复用，只限于符合范围条件的数据，而当整个页从B+树里面摘掉以后，可以复用到任何位置，如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一 个数据页就被标记为可复用，delete命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件 的大小是不会变的，经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的，而重建表，就可以达到这样的目的，alter语句在启动的时候需要获取MDL写锁，但是这个写锁在真正拷贝数据之前就退化成读锁了，那为什么不干脆直接解锁呢?为了保护自己，禁止其他线程对这个表同时做DDL

### mysql崩溃恢复

binlog写完，redo log还没commit前发生 crash，如果redolog里面的事务是完整的，也就是已经有了commit标识，则直接提交，如果redolog里面的事务只有完整的prepare，则判断对应的事务binlog是否存在并完整，如果是，则提交事务，否则，回滚事务

#### MySQL怎么判断binlog是完整的

一个事务的binlog是有完整格式的

1. statement格式的binlog，最后会有COMMIT

2. row格式的binlog，最后会有一个XID event

3. 在MySQL 5.6.2版本以后，还引入了binlog-checksum参数，用来验证binlog内容的正确 性。对于binlog日志由于磁盘原因，可能会在日志中间出错的情况，MySQL可以通过校验

   checksum的结果来发现

#### redo log 和 binlog是怎么关联

它们有一个共同的数据字段，叫XID。崩溃恢复的时候，会按顺序扫描redo log

1. 如果碰到既有prepare、又有commit的redo log，就直接提交
2. 如果碰到只有parepare、而没有commit的redo log，就拿着XID去binlog找对应的事务

#### 处于prepare阶段的redo log加上完整binlog，重启就能恢复，MySQL为什么要这么设计

数据与备份的一致性有关。在binlog写完以后MySQL发生崩溃，这时候binlog已经写入了，之后就会被从库(或者用这个 binlog恢复出来的库)使用，所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性

#### 只用redo log，不要binlog

如果只从崩溃恢复的角度来讲是可以的。你可以把binlog关掉，这样就没有两阶段提交 了，但系统依然是crash-safe的

#### redolog

1. redo log用于保证crash-safe能力。innodb_flush_log_at_trx_commit这个参数设置成1的时候， 表示每次事务的redo log都直接持久化到磁盘。这个参数建议设置成1，这样可以保证 MySQL异常重启之后数据不丢失

### 事务的ACID特性

#### 原子性

一个事务必须被视为一个不可分割的最小工作单元，整个事务中的所有操作要么全部提交成功，要么全部失败回滚

#### 一致性

数据库总是从一个一致性的状态转移到另外一个一致性的状态，因为事务最终没有提交，所以事务中所做的修改也不会保存到数据库中

#### 隔离性

通常来说，一个事务所做的修改在最终提交以前，对其他事务是不可见的

#### 持久性

一旦事务提交，则其所做的修改就会永久保存到数据库中，即使系统崩溃，修改的数据也不会丢失(不可能有能做到100%的持久性保证策略)



### 索引

InnoDB的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候， 并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在InnoDB中，每个数据页的大小默认是16KB

1. 哈希索引，哈希表这种结构适用于只有等值查询的场景，比如Memcached及其他一些NoSQL引擎
2. 有序数组，有序数组在等值查询和范围查询场景中的性能就都非常优秀，在需要更新数据的时候就麻烦 了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高，有序数组索引只适用于静态存储引擎
3. 二叉搜索树，二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上，为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N叉”树。这里，“N叉”树中的“N”取决于数据块的大小

#### InnoDB 的索引模型

在InnoDB中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表

1. 主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为聚簇索引(clustered index)
2. 非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引 (secondary index)

#### 索引维护

B+树为了维护索引有序性，在插入新值的时候需要做必要的维护，需要申请一个新的 数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响，除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中， 整体空间利用率降低大约50%，当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合 并的过程，可以认为是分裂过程的逆过程

1. 自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂
2. 而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高
3. 主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小
4. 由于InnoDB是索引组织表，一般情况下建议创建一个自增主键，这样非主键索引占用的 空间最小
5. 只有一个索引，该索引必须是唯一索引适合用业务字段直接做主键
6. 由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用 的性能优化手段

#### 最左前缀原则

1. B+树这种索引结构，可以利用索引的“最左前缀”，来定位记录，这个最左 前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符
2. 索引项是按照索引定义里面出现的字段顺序排序的

#### 联合索引

评估标准是，索引的复用能力以及空间占用

1. 第一原则是，如果通过调整顺序，可 以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的

#### 索引下推

1. 在MySQL 5.6之前，只能从找到满足条件的索引开始一个个回表。到主键索引上找出数据行，再对比字段值
2. 而MySQL 5.6 引入的索引下推优化(index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数

#### 查询过程

先是通过B+树从树根开始，按层搜索到叶子节点的这个数据页，然后可以认为数据页内部通过二分法来定位记录，因为引擎是按页读写的，所以说，当找到满足条件的记录的时候，它所在的数据页就都在内存里了。 那么，对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算，如果这个记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，这个操作会稍微复杂一些

1. 对于普通索引来说，查找到满足条件的第一个记录后，需要查找下一个记录，直到碰到第一个不满足条件的记录
2. 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继 续检索

#### 更新过程

当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中 的话，在不影响数据一致性的前提下，InooDB会将这些更新操作缓存在change buffer中，这样 就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内 存，然后执行change buffer中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性，虽然名字叫作change buffer，实际上它是可以持久化的数据。也就是说，change buffer在内存中有拷贝，也会被写入到磁盘上，将change buffer中的操作应用到原数据页，得到最新结果的过程称为merge。除了访问这个数据 页会触发merge外，系统有后台线程会定期merge。在数据库正常关闭(shutdown)的过程中，也会执行merge操作，如果能够将更新操作先记录在change buffer，减少读磁盘，语句的执行速度会得到明显 的提升。而且，数据读入内存是需要占用buffer pool的，所以这种方式还能够避免占用内存，提高内存利用率

1. 对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用change buffer 了，因此唯一索引的更新就不能使用change buffer，实际上也只有普通索引可以使用。
2. 普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的CPU时间
3. redo log 主要节省的是随 机写磁盘的IO消耗(转成顺序写)，而change buffer主要节省的则是随机读磁盘的IO消耗

#### 索引选择

普通索引和唯一索引应该怎么选择。其实，这两类索引在查询能力上 是没差别的，主要考虑的是对更新性能的影响。所以，建议尽量选择普通索引，如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭change buffer。而在其他情况下，change buffer都能提升更新性能，普通索引和change buffer的配合使用，对于数据量大的表的更新优化还是很明显的

#### 选错索引

MySQL会根据词法解析的结果分析出可能可以使用的索引作为候选项，然后在候选列表中依次判断每个索引需要扫描多少行，MySQL在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数，这个统计信息就是索引的“区分度”。显然，一个索引上不同的值越多，这个索引的区分度就越好，而一个索引上不同的值的个数，我们称之为“基数”，mysql采用采样的方法得到基数，因为把整张表取出来一行行统计，虽然可以得到精确的结果，但是代价太高了，所以只能选择“采样统计”，采样统计的时候，InnoDB默认会选择N个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。对于由于索引统计信息不准确导致的问题，你可以用analyze table来解决，而对于其他优化器误判的情况，你可以在应用端用force index来强行指定索引，也可以通过修改语句来引导优化器，还可以通过增加或者删除索引来绕过这个问题，主键是直接按照表的行数来估计的。而表的行数，优化器直接用的是 show table status的值

#### 前缀索引

使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本，实际上，我们在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少。因此，我们可以通过统计索引上有多少个不同的值来判断要使用多长的前缀，使用前缀索引就用不上覆盖索引对查询性能的优化了

#### 字符串索引

1. 直接创建完整索引，这样可能比较占用空间
2. 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引
3. 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题
4. 创建hash字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支 持范围扫描

#### 不走索引

1. 对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃对走树搜索功能，优化器并不是要放弃使用这个索引，而是扫描整个索引树
2. 隐式类型转换，mylsq会将字符串转为数字进行比较，会对索引字段做函数操作，优化器会放弃走树搜索功能
3. 隐式字符编码转换，先把utf8字符串转成utf8mb4字符集，再做比较，字符集不同只是条件之一，连接过程中要求在被驱动表的索引字段 连 上加函数操作 上 ，是直接导致对被驱动表做全表扫描的原因

### 锁

当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致 这几个线程都进入无限等待的状态，称为死锁

#### 两种策略

1. 一种策略是，直接进入等待，直到超时，超时时间设置不能太短，太短的话，会出现很多误伤
2. 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行

#### 死锁检测

每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是O(n)的操作，死锁检测要耗费大量的CPU资源

1. 如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉
2. 另一个思路是控制并发度，比如同一行同时最多只有10个线程在更新，那么死锁检测的成本很低
3. 通过将一行改成逻辑上的多行来减少锁冲突

#### 解决办法

1. 检测到死锁的循环依赖，立即返回一个错误
2. 当查询的时间达到锁等待超时的设定后放弃锁请求
3. Innodb是将持有最少行级排他锁的事务进行回滚

### 事务

begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作InnoDB表 的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用start transaction with consistent snapshot 这个命令

#### READ VIEW

InnoDB在实现MVCC时用到的一致性读视图，即consistent read view，用于支持

RC(Read Committed，读提交)和RR(Repeatable Read，可重复读)隔离级别的实现。

它没有物理结构，作用是事务执行期间用来定义“我能看到什么数据”，在实现上， InnoDB为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活 跃”的所有事务ID。“活跃”指的就是，启动了但还没提交，数组里面事务ID的最小值记为低水位，当前系统里面已经创建过的事务ID的最大值加1记为高水位，这个视图数组和高水位，就组成了当前事务的一致性视图(read-view)，而数据版本的可见性规则，就是基于数据的row trx_id和这个一致性视图的对比结果得到的

#### MVCC

InnoDB里面每个事务有一个唯一的事务ID，叫作transaction id。它是在事务开始的时候向InnoDB的事务系统申请的，是按申请顺序严格递增的，而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且 把transaction id赋值给这个数据版本的事务ID，记为row trx_id。同时，旧的数据版本要保留， 并且在新的数据版本中，能够有信息可以直接拿到它，也就是说，数据表中的一行记录，其实可能有多个版本(row)，每个版本有自己的row trx_id

3. 

##### 当前读

更新数据都是先读后写的，而这个读，只能读当前的 值，称为“当前读”(current read)，否则可能造成其他事务的丢失更新，除了update语句外，select语句如果加锁，也是当前读

### 可重复读

按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这 个事务执行期间，其他事务的更新对它不可见

#### 实现

可重复读的核心就是一致性读(consistent read);而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待

#### 与读提交区别

1. 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询 都共用这个一致性视图

2. 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图

   为什么表结构不支持“可重复读”?这是因为表结构没有对应的行数据，也没有 row trx_id，因此只能遵循当前读的逻辑

### 怎么删除表的前10000行

在一个连接中循环执行20次 delete from T limit 500

### 事务日志

事务日志可以帮助提高事务的效率，使用事务日志，存储引擎在修改表的数据时只需要修改其内存拷贝，再把该修改行为记录持久到硬盘上的事务日志中，而不用每次都将修改的数据本身持久到磁盘，事务日志采用的是追加的方式，，因此写日志的操作是磁盘上一小块区域的顺序io，事务日志持久化后，内存中被修改的数据在后台可以慢慢地刷回到磁盘，通常称为预写日志，修改数据需要写两次磁盘，如果数据的修改已经记录到事务日志并持久化，但数据本身还没有写回磁盘，此时系统崩溃，存储引擎在重启时能够自动恢复这部分修改的数据

### 两阶段锁定协议

在事务执行过程中，随时都可以执行锁定，但锁只有在执行commit或者rollback时才会释放，并且所有的锁是在同一时刻被释放

### MVCC

MVCC的实现，是通过保存数据在某个时间点的快照来实现的，不管需要执行多长时间，每个事务看到的数据都是一致的，根据事务的开始时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的，MVCC只在READ COMMITTED和REPEATABLE READ两个隔离级别下工作

#### Inonodb的实现

Innodb的MVCC，是通过在每行记录后面保存两个隐藏的列来实现的，这两个列，一个保存了行的创建版本号，一个保存行的删除版本号，每开始一个新的事务，系统版本号都会自动递增，事务开始时刻的版本号会作为事务的版本号，insert：innodb为新插入的每一行保存当前系统版本号作为行版本号，delete：innodb为删除的每一行保存当前系统版本号作为行删除标识，update：innodb为插入一行新记录，保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为行删除标识

#### RR级别MVCC

Innodb会根据以下两个条件检查每行记录

1. Innodb只查找版本早于当前事务版本的数据行(也就是说，行的系统版本号小于等于事务的系统版本号)，这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的
2. 行的删除版本要么未定义，要么大于当前事务版本号，这样可以确保事务读取到的行，在事务开始之前未被删除

### Innodb底层机制

#### 刷盘

当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”，InnoDB用缓冲池 (buffer pool)管理内存，buffer pool位于存储引擎层，查询缓存位于server层

1. 当InnoDB的redo log写满了，这时候系统会停止所有更新操作，把 checkpoint往前推进，redo log留出空间可以继续写，把checkpoint位置从CP推进到CP’，就需要将两个点之间的日志对应的所有脏页都flush到磁盘上
2. 当系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘
3. 当MySQL认为系统“空闲”的时候
4. 当MySQL正常关闭的情况。这时候，MySQL会把内存的脏页都flush到磁 盘上，这样下次MySQL启动的时候，就可以直接从磁盘上读数据，启动速度会很快

##### 对性能的影响

InnoDB的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久 不使用的数据页从内存中淘汰掉:如果要淘汰的是一个干净页，就直接释放出来复用;但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用，无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用IO资源 并可能影响到了你的更新语句，都可能是造成你从业务端感知到MySQL“抖”了一下的原因，一旦一个查询请求需要在执行过程中先flush掉一个脏页时，这个查询就可能要比平时慢了。而 MySQL中的一个机制，可能让你的查询会更慢:在准备刷一个脏页的时候，如果这个数据页旁 边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉;而且这个把“邻居”拖下水的逻辑还 可以继续蔓延，这个优化在机械硬盘时代是很有意义的，可以减少很多随机IO

#### InnoDB刷脏页的控制策略

当前的脏页比例，redo log写入速度

#### 参数innodb_file_per_table

表数据既可以存在共享表空间里，也可以是单独的文件，建议将这个值设置为ON。因为，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过drop table命令，系统就会直接删除这个文 件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的

### select count(*)慢

#### 实现方式

1. MyISAM引擎把一个表的总行数存在了磁盘上，因此执行count(*)的时候会直接返回这个数，效率很高，如果加了where 条件 

   的话，MyISAM表也是不能返回得这么快的

2. 而InnoDB引擎就麻烦了，它执行count()的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数，InnoDB是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是 主键值。所以，普通索引树比主键索引树小很多。对于count()这样的操作，遍历哪个索引树得 到的结果逻辑上都是一样的。因此，MySQL优化器会找到最小的那棵树来遍历。在保证逻辑在确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。

#### 解决办法

1. 用缓存系统保存计数，有丢失数据和计数不精确的问题，把计数放在Redis里面，不能够保证计数和MySQL表里的数据精确一致的原因，是这两个这 不同的存储构成的系统，不支持分布式事务，无法拿到精确一致的视图
2. 在数据库保存计数，而把计数值也放在MySQL中，就解决了一致性视图的问题

#### 不同count区别

count()是一个聚合函数，对于返回的结果集，一行行地 判断，如果count函数的参数不是NULL，累计值就加1，否则不加。最后返回累计值，按照效率排序的话，count(字段)<count(主键id)<count(1)≈count(*)，所以建议尽量使用count(*)

1. 对 count( 主键id) 说来 ，InnoDB引擎会遍历整张表，把每一行的id值都取出来，返回给server 层。server层拿到id后，判断是不可能为空的，就按行累加
2. 对 count(1) 来说 ，InnoDB引擎遍历整张表，但不取值。server层对于返回的每一行，放一个 数字“1”进去，判断是不可能为空的，按行累加
3. 对 count(字段)来说，如果这个“字段”是定义为not null的话，一行行地从记录里面读出这个字段，判断不能为null，按行累加，如果这个“字段”定义允许为null，那么执行的时候，判断到有可能是null，还要把值取出来再判断一下，不是null才累加
4. 但 count(星)是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(星)肯定不是null，按行累加

### order by

sort_buffer_size，就是MySQL为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量 小于sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序，外部排序一般使用归并排序算法。可以这么简单理 解，MySQL 将需要排序的数据分成 将 12份，每一份单独排序后存在这些临时文件中。然后把 份 这12个有序文件再合并成一个有序的大文件

#### 全字段排序 全 VS rowid V 排序

如果MySQL实在是担心排序内存太小，会影响排序效率，才会采用rowid排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据，如果MySQL认为内存足够大，会优先选择全字段排序，把需要的字段都放到sort_buffer中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据

### 查询一行慢

#### 长时间不返回

1. 等MDL锁，这个状态表示的是，现在有一个线程正在表上请求或者持有MDL写锁，把select语句堵住了
2. 等flush，flush tables t with read lock;表示关闭表t，这个语句执行起来都很快，除非它们也被别的线程堵住了
3. 等行锁

#### 查询慢

1. 没有索引
2. 大批量更新，删除产生大量undo log

### 幻读

幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行，幻读仅专指“新插入的行”

1. 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的
2. 幻读在“当前读”下才会出现

#### 原因

即使把所有的记录都加上锁，还是阻止不了新插入的记录， 这也是为什么“幻 读”会被单独拿出来解决的原因

1. 产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB只好引入新的锁，也就是间隙锁(Gap Lock)

#### 间隙锁

间隙锁，锁的就是两个值之间的空隙

1. 跟间隙锁存在冲突关系的，是跟 “往这个间隙中插入一个记录往 ”这个操作，间隙锁之间都不存在冲突关系
2. 间隙锁和行锁合称next-key lock，每个next-key lock是前开后闭区间

### 锁

#### 加锁规则

1. 加锁的基本单位是next-key lock，前开后闭
2. 查找过程中访问到的对象才会加锁
3. 索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁
4. 索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁
5. 唯一索引上的范围查询会访问到不满足条件的第一个值为止
6. 锁是加在索引上的；同时，它给我们的指导是，如果你要用lock in share mode 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中加入索引中不存在的字段
7. 在删除数据的时候尽量加在 limit 1。这样不仅可以控制删除数据的条数，让操作更安全，还可以减小加锁的范围
8. next key lock是要分成间隙锁和行锁两段来执行的
9. 在读提交隔离级别下还有一个优化，即：语句执行过程中加上的行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交

### 问题处理

#### 短连接风暴

1. 先处理掉那些占着连接但是不工作的线程，对于那些不需要保持的连接，我们可以通过kill connection主动踢掉
2. 减少连接过程的消耗，有的业务代码会在短时间内先大量申请数据库连接做备用，如果现在数据库确认是被连接行为打挂了，那么一种可能的做法，是让数据库跳过权限验证阶段

#### 慢查询性能问题

##### 索引没有设计好

1. 一般就是通过紧急创建索引来解决，比较理想的是能够在备库先执行

##### SQL语句没写好

1. MySQL 5.7提供了query_rewrite功能，可以把输入的一种语句改写成另外一种模式

##### MySQL选错了索引

1. 应急方案就是给这个语句加上force index

#### QPS突增问题

新功能bug引起的

### binlog

#### 写入机制

事务执行过程中，先把日志写到binlog cache，事务提交的时候，再把binlog cache写到binlog文件中，一个事务的binlog是不能被拆开的，因此不论这个事务多大，也要确保一次性写入

1. 系统给binlog cache分配了一片内存，每个线程一个，每个线程有自己binlog cache，但是共用同一份binlog文件，参数 binlog_cache_size用于控制单个线程内binlog cache所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘
2. 事务提交的时候，执行器把binlog cache里的完整事务写入到binlog中，并清空binlog cache

### redo log

#### 写入机制

事务在执行过程中，生成的redo log是要先写到redo log buffer的

1. 事务执行中间过程的redo log也是直接写在redo log buffer中的，这些redo log也会被后台线程一起持久化到磁盘。也就是说，一个没有提交的事务的redo log，也是可能已经持久化到磁盘的
2. 除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的redo log写入到磁盘中，innodb_log_buffer_size占用的空间即将达到占 innodb_log_buffer_size 一半的时候，后台线程会主动写盘，并行的事务提交的时候，顺带将这个事务的redo log buffer持久化到磁盘
3. redo log在prepare阶段就要持久化一次，因为有一个崩溃恢复逻辑是要依赖于prepare 的redo log，再加上binlog来恢复的

WAL机制主要得益于两个方面，redo log 和 binlog都是顺序写，磁盘的顺序写比随机写速度要快，组提交机制，可以大幅度降低磁盘的IOPS消耗

#### 三种格式对比

##### statement

1. statement格式下，记录到binlog里的是语句原文
2. delete语句加limit可能会导致主从不一致，因为主从库上执行的sql用到的索引不一样

##### row

缺点是很占空间，优点是恢复数据，因为记录了字段的信息

1. row格式的binlog里没有了SQL语句的原文，而是替换成了两个event：Table_map和Delete_rows
2. 当binlog_format使用row格式的时候，binlog里面记录了真实删除行的主键id，这样binlog传到备库去的时候，不会有主备删除不同行的问题

##### mixed

MySQL自己会判断这条SQL语句是否可能引起主备不一致，如果有可能，就用row格式，否则就用statement格式

### MySQL主备的基本原理

备库设置成readonly状态，readonly设置对超级(super)权限用户是无效的，而用于同步更新的线程，就拥有超级权限

1. 在备库B上通过change master命令，设置主库A的IP、端口、用户名、密码，以及要从哪个位置开始请求binlog，这个位置包含文件名和日志偏移量
2. 在备库B上执行start slave命令，这时候备库会启动两个线程，就是io_thread和sql_thread。其中io_thread负责与主库建立连接
3. 主库A校验完用户名、密码后，开始按照备库B传过来的位置，从本地读取binlog，发给B
4. 备库B拿到binlog后，写到本地文件，称为中转日志（relay log）
5. sql_thread读取中转日志，解析出日志里的命令，并执行

#### 双M结构

互为主备，备库执行relay log 后也会生成binlog，然后发送给从库，会有循环复制的问题

##### 解决办法

1. 规定两个库的server id必须不同，如果相同，则它们之间不能设定为主备关系
2. 一个备库接到binlog并在重放的过程中，生成与原binlog的server id相同的新的binlog
3. 每个库在收到从自己的主库发过来的日志后，先判断server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志

#### 主从延迟

在网络正常的时候，日志从主库传给备库所需的时间是很短的，主备延迟的主要来源是备库接收完binlog和执行完这个事务之间的时间差，主备延迟最直接的表现是，备库消费中转日志（relay log）的速度，比主库生产binlog的速度要慢

1. 有些部署条件下，备库所在机器的性能要比主库所在的机器性能差
2. 备库压力大，一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力，通过binlog输出到外部系统，比如Hadoop这类系统，让外部系统提供统计类查询的能力
3. 大事务(一次性用delete语句删除太多数据，大表DDL)，因为主库上必须等事务执行完成才会写入binlog，再传给备库

#### 主备切换策略

1. 可靠性优先策略，切换流程中是有不可用时间的
2. 可用性优先策略，可能出现数据不一致的情况

### mysql并行复制策略

1. 按表分发策略，按表分发事务的基本思路是，如果两个事务更新不同的表，它们就可以并行。因为数据是存储在 表里的，所以按表分发，可以保证两个worker不会更新同一行
2. 按行分发策略，如果 两个事务没有更新相同的行，它们在备库上可以并行执行。显然，这个模式要求binlog格式必须 是row，相比于按表并行分发策略，按行并行策略在决定线程分发的时候，需要消耗更多的计算资源

#### semi-sync

1. 事务提交的时候，主库把binlog发给从库
2. 从库收到binlog以后，发回给主库一个ack，表示收到了
3. 主库收到这个ack以后，才能给客户端返回“事务完成”的确认

### 读写分离问题

#### 过期读

1. 强制走主库方案，对于必须要拿到最新结果的请求，强制将其发到主库上，
2. Sleep 方案，主库更新后，读从库之前先sleep一下

### 避免死锁

1. 由于锁是一个个加的，要避免死锁，对同一组资源，要按照尽量相同的顺序访问
2. 在发生死锁的时刻，forupdate这条语句占有的资源更多，回滚成本更大，所以InnoDB选 择了回滚成本更小的lock in share mode语句，来回滚

### 大查询会不会导致oom

1. 由于MySQL采用的是边算边发的逻辑，因此对于数据量很大的查询结果来说，不会在server端保存完整的结果集。所以，如果客户端读结果不及时，会堵住MySQL的查询过程，但是不会把内存打爆
2. 而对于InnoDB引擎内部，由于有淘汰策略，大查询也不会导致内存暴涨。并且，由于InnoDB对LRU算法做了改进，冷数据的全表扫描，对Buffer Pool的影响也能做到可控
3. 于InnoDB对Bufffer Pool的LRU算法做了优化，即：第一次从磁盘读入内存的数据页，会先放在old区域。如果1秒之后这个数据页不再被访问了，就不会被移动到LRU链表头部，这样对Buffer Pool的命中率影响就不大

### join

1. 使用join语句，性能比强行拆成多个单表执行SQL语句的性能要好，前提是“可以使用被驱动表的索引”
2. 如果使用join语句的话，需要让小表做驱动表

#### 能不能用join

1. 如果可以使用IndexNested-Loop Join算法，也就是说可以用上被驱动表上的索引，其实是没问题的
2. 如果使用Block Nested-Loop Join算法，扫描行数就会过多。尤其是在大表上的join操作，这 样可能要扫描被驱动表很多次，会占用大量的系统资源。所以这种join尽量不要用

所以在判断要不要使用join语句时，就是看explain结果里面，Extra字段里面有没有出现“Block Nested Loop”字样，在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，在滤完成之后，计算参与join的各个字段的总数据量，数据量小的那个表，就是“小表 ”，应该 ， 作为驱动表

#### MRR优化

因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键 因的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能

1. 根据索引a，定位到满足条件的记录，将id值放入read_rnd_buffer中
2. 将read_rnd_buffer中的id进行递增排序
3. 排序后的id数组，依次到主键id索引中查记录，并作为结果返回
4. 如果步骤1 中，read_rnd_buffer放满了，就会先执行完步骤2和3，然后清空read_rnd_buffer。之后继续找索引a的下个记录，并继续循环

### group by

group by逻辑都需要构造一个带唯一索引的表，执行代价都是比较高的

#### 优化

1. 如果对group by语句的结果没有排序要求，要在语句后面加 order by null
2. 尽量让group by过程用上表的索引，确认方法是explain结果里没有Using temporary和 Using filesort
3. 如果group by需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大tmp_table_size参数，来避免用到磁盘临时表
4. 如果数据量实在太大，使用SQL_BIG_RESULT这个提示，来告诉优化器直接使用排序算法得到group by的结果

### 自增值

1. MyISAM引擎的自增值保存在数据文件中，InnoDB引擎的自增值，其实是保存在了内存里，并且到了MySQL 8.0版本后，才有了“自增值持久化”的能力，将自增值的变更记录在了redo log中，重启的时候依靠redo log恢复重启之前的值

#### 自增值修改机制

1. 如果插入数据时id字段指定为0、null 或未指定值，那么就把这个表当前的AUTO_INCREMENT值填到自增字段
2. 如果插入数据时id字段指定了具体的值，就直接使用语句里指定的值

#### 不连续原因

1. 唯一键冲突是导致自增主键 id不连续的第一种原因
2. 事务回滚也会产生类似的现象，这就是第二种原因
3. 对于批量插入数据的语句，MySQL有一个批量申请自增id的策略，同一个语句去申请自增id，每次申请到的自增id个数都是上一次的两倍，这是主键id出现自增不连续的第三种原因

#### 自增id不能回退原因

1. 每次申请id之前，先判断表里面是否已经存在这个id。如果存在，就跳过这个id。但是，这个方法的成本很高。因为，本来申请id是一个很快的操作，现在还要再去主键索引树上判断id是否存在
2. 把自增id的锁范围扩大，必须等到一个事务执行完成并提交，下一个事务才能再申请自增id。这个方法的问题，就是锁的粒度太大，系统并发能力大大下降

### 其他

1. grant语句会同时修改数据表和内存，判断权限的时候使用的是内存数据。因此，规范地使用grant和revoke语句，是不需要随后加上flush privileges语句的
2. flush privileges语句本身会用数据表的数据重建一份内存权限数据，所以在权限数据可能存在不一致的情况下再使用。而这种不一致往往是由于直接用DML语句操作系统权限表导致的，所以我们尽量不要使用这类语句
